# dataset_manager.py - ë°ì´í„°ì…‹ ê´€ë¦¬
"""
YOLOv8 í™”ì¬ ë° ì—°ê¸° ê°ì§€ í”„ë¡œì íŠ¸ ë°ì´í„°ì…‹ ê´€ë¦¬ ëª¨ë“ˆ
"""

import os
import glob
import shutil
import random
from pathlib import Path
from PIL import Image
import matplotlib.pyplot as plt
from config import Config


class DatasetManager:
    """ë°ì´í„°ì…‹ ê´€ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.base_path = Config.DATASET_BASE_PATH
        self.dataset_paths = Config.get_dataset_paths()
        self.label_paths = Config.get_label_paths()

    def create_directory_structure(self):
        """ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        print("=== ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ===")

        # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ìƒì„±
        for split, path in self.dataset_paths.items():
            os.makedirs(path, exist_ok=True)
            print(f"âœ… ìƒì„±: {path}")

        # ë¼ë²¨ ë””ë ‰í† ë¦¬ ìƒì„±
        for split, path in self.label_paths.items():
            os.makedirs(path, exist_ok=True)
            print(f"âœ… ìƒì„±: {path}")

        print("ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ!\n")

    def check_dataset_status(self):
        """ë°ì´í„°ì…‹ ìƒíƒœ í™•ì¸"""
        print("=== ë°ì´í„°ì…‹ ìƒíƒœ í™•ì¸ ===")

        total_images = 0
        total_labels = 0

        for split in ['train', 'val', 'test']:
            img_path = self.dataset_paths[split]
            label_path = self.label_paths[split]

            # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
            image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
            images = []
            for ext in image_extensions:
                images.extend(glob.glob(os.path.join(img_path, ext)))
                images.extend(glob.glob(os.path.join(img_path, ext.upper())))

            # ë¼ë²¨ íŒŒì¼ í™•ì¸
            labels = glob.glob(os.path.join(label_path, '*.txt'))

            num_images = len(images)
            num_labels = len(labels)

            total_images += num_images
            total_labels += num_labels

            print(f"{split.upper():5} - ì´ë¯¸ì§€: {num_images:4}ê°œ, ë¼ë²¨: {num_labels:4}ê°œ")

            # ë°ì´í„° ë¶ˆê· í˜• í™•ì¸
            if num_images > 0 and num_labels > 0:
                if num_images != num_labels:
                    print(f"  âš ï¸  {split} ì„¸íŠ¸ì—ì„œ ì´ë¯¸ì§€ì™€ ë¼ë²¨ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")

        print(f"\nì´ ì´ë¯¸ì§€: {total_images}ê°œ, ì´ ë¼ë²¨: {total_labels}ê°œ")

        if total_images == 0:
            print("âŒ ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            self._print_upload_instructions()

        return {
            'total_images': total_images,
            'total_labels': total_labels,
            'has_data': total_images > 0
        }

    def _print_upload_instructions(self):
        """ë°ì´í„° ì—…ë¡œë“œ ì•ˆë‚´"""
        print("\n=== ë°ì´í„° ì—…ë¡œë“œ ì•ˆë‚´ ===")
        print("1. Roboflowì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ:")
        print("   URL: https://universe.roboflow.com/custom-thxhn/fire-wrpgm/dataset/8")
        print("\n2. Google Driveì— ë‹¤ìŒ êµ¬ì¡°ë¡œ ì—…ë¡œë“œ:")
        print(f"   {self.base_path}/")
        print("   â”œâ”€â”€ train/")
        print("   â”‚   â”œâ”€â”€ images/  (í›ˆë ¨ ì´ë¯¸ì§€)")
        print("   â”‚   â””â”€â”€ labels/  (í›ˆë ¨ ë¼ë²¨ .txt)")
        print("   â”œâ”€â”€ valid/")
        print("   â”‚   â”œâ”€â”€ images/  (ê²€ì¦ ì´ë¯¸ì§€)")
        print("   â”‚   â””â”€â”€ labels/  (ê²€ì¦ ë¼ë²¨ .txt)")
        print("   â””â”€â”€ test/")
        print("       â”œâ”€â”€ images/  (í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€)")
        print("       â””â”€â”€ labels/  (í…ŒìŠ¤íŠ¸ ë¼ë²¨ .txt)")

    def visualize_dataset_samples(self, num_samples=4):
        """ë°ì´í„°ì…‹ ìƒ˜í”Œ ì‹œê°í™”"""
        print("=== ë°ì´í„°ì…‹ ìƒ˜í”Œ ì‹œê°í™” ===")

        # í›ˆë ¨ ë°ì´í„°ì—ì„œ ìƒ˜í”Œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
        train_images = glob.glob(os.path.join(self.dataset_paths['train'], '*'))

        if len(train_images) == 0:
            print("ì‹œê°í™”í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ëœë¤ ìƒ˜í”Œ ì„ íƒ
        sample_images = random.sample(train_images, min(num_samples, len(train_images)))

        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        axes = axes.flatten()

        for i, img_path in enumerate(sample_images):
            if i >= len(axes):
                break

            try:
                # ì´ë¯¸ì§€ ë¡œë“œ
                image = Image.open(img_path)
                axes[i].imshow(image)
                axes[i].set_title(f"Sample {i + 1}: {os.path.basename(img_path)}")
                axes[i].axis('off')

                # ëŒ€ì‘í•˜ëŠ” ë¼ë²¨ íŒŒì¼ í™•ì¸
                base_name = os.path.splitext(os.path.basename(img_path))[0]
                label_path = os.path.join(self.label_paths['train'], f"{base_name}.txt")

                if os.path.exists(label_path):
                    with open(label_path, 'r') as f:
                        labels = f.readlines()
                    axes[i].set_xlabel(f"Labels: {len(labels)} objects")
                else:
                    axes[i].set_xlabel("No label file found")

            except Exception as e:
                axes[i].text(0.5, 0.5, f'Error loading image:\n{str(e)}',
                             ha='center', va='center', transform=axes[i].transAxes)
                axes[i].set_title(f"Error: {os.path.basename(img_path)}")

        plt.tight_layout()
        plt.show()

    def analyze_class_distribution(self):
        """í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„"""
        print("=== í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„ ===")

        class_counts = {name: 0 for name in Config.CLASS_NAMES}
        total_objects = 0

        # ëª¨ë“  ë¼ë²¨ íŒŒì¼ í™•ì¸
        for split in ['train', 'val', 'test']:
            label_files = glob.glob(os.path.join(self.label_paths[split], '*.txt'))

            for label_file in label_files:
                try:
                    with open(label_file, 'r') as f:
                        lines = f.readlines()

                    for line in lines:
                        parts = line.strip().split()
                        if len(parts) >= 5:  # YOLO í˜•ì‹: class_id x y w h
                            class_id = int(parts[0])
                            if 0 <= class_id < len(Config.CLASS_NAMES):
                                class_counts[Config.CLASS_NAMES[class_id]] += 1
                                total_objects += 1

                except Exception as e:
                    print(f"ë¼ë²¨ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ {label_file}: {e}")

        # ê²°ê³¼ ì¶œë ¥
        print(f"ì´ ê°ì²´ ìˆ˜: {total_objects}")
        for class_name, count in class_counts.items():
            percentage = (count / total_objects * 100) if total_objects > 0 else 0
            print(f"{class_name:10}: {count:5}ê°œ ({percentage:5.1f}%)")

        # ì‹œê°í™”
        if total_objects > 0:
            plt.figure(figsize=(10, 6))
            classes = list(class_counts.keys())
            counts = list(class_counts.values())

            plt.bar(classes, counts)
            plt.title('Class Distribution in Dataset')
            plt.xlabel('Classes')
            plt.ylabel('Number of Objects')

            # ë°±ë¶„ìœ¨ í‘œì‹œ
            for i, count in enumerate(counts):
                percentage = count / total_objects * 100
                plt.text(i, count + max(counts) * 0.01, f'{percentage:.1f}%',
                         ha='center', va='bottom')

            plt.tight_layout()
            plt.show()

        return class_counts

    def validate_dataset_format(self):
        """ë°ì´í„°ì…‹ í˜•ì‹ ê²€ì¦"""
        print("=== ë°ì´í„°ì…‹ í˜•ì‹ ê²€ì¦ ===")

        issues = []

        for split in ['train', 'val', 'test']:
            print(f"\n{split.upper()} ë°ì´í„° ê²€ì¦ ì¤‘...")

            image_files = []
            for ext in ['*.jpg', '*.jpeg', '*.png']:
                image_files.extend(glob.glob(os.path.join(self.dataset_paths[split], ext)))

            for img_file in image_files:
                base_name = os.path.splitext(os.path.basename(img_file))[0]
                label_file = os.path.join(self.label_paths[split], f"{base_name}.txt")

                # ë¼ë²¨ íŒŒì¼ ì¡´ì¬ í™•ì¸
                if not os.path.exists(label_file):
                    issues.append(f"Missing label for {img_file}")
                    continue

                # ë¼ë²¨ í˜•ì‹ ê²€ì¦
                try:
                    with open(label_file, 'r') as f:
                        lines = f.readlines()

                    for line_num, line in enumerate(lines, 1):
                        parts = line.strip().split()
                        if len(parts) != 5:
                            issues.append(f"Invalid format in {label_file}:{line_num}")
                            continue

                        # YOLO í˜•ì‹ ê²€ì¦
                        try:
                            class_id = int(parts[0])
                            x, y, w, h = map(float, parts[1:])

                            if not (0 <= class_id < Config.NUM_CLASSES):
                                issues.append(f"Invalid class_id {class_id} in {label_file}:{line_num}")

                            if not all(0 <= val <= 1 for val in [x, y, w, h]):
                                issues.append(f"Invalid bbox coordinates in {label_file}:{line_num}")

                        except ValueError:
                            issues.append(f"Invalid number format in {label_file}:{line_num}")

                except Exception as e:
                    issues.append(f"Error reading {label_file}: {e}")

        # ê²€ì¦ ê²°ê³¼ ì¶œë ¥
        if issues:
            print(f"\nâŒ {len(issues)}ê°œì˜ ë¬¸ì œ ë°œê²¬:")
            for issue in issues[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
                print(f"  - {issue}")
            if len(issues) > 10:
                print(f"  ... ê·¸ë¦¬ê³  {len(issues) - 10}ê°œ ë”")
        else:
            print("\nâœ… ë°ì´í„°ì…‹ í˜•ì‹ ê²€ì¦ ì™„ë£Œ! ë¬¸ì œ ì—†ìŒ")

        return len(issues) == 0

    def split_dataset(self, source_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):
        """ë°ì´í„°ì…‹ ë¶„í•  (ì´ë¯¸ ë¶„í• ëœ ë°ì´í„°ê°€ ì—†ì„ ë•Œ ì‚¬ìš©)"""
        if train_ratio + val_ratio + test_ratio != 1.0:
            print("âŒ ë¹„ìœ¨ì˜ í•©ì´ 1.0ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
            return

        print(f"=== ë°ì´í„°ì…‹ ë¶„í•  (Train: {train_ratio}, Val: {val_ratio}, Test: {test_ratio}) ===")

        # ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png']:
            image_files.extend(glob.glob(os.path.join(source_dir, 'images', ext)))

        # ëœë¤ ì…”í”Œ
        random.shuffle(image_files)

        total_files = len(image_files)
        train_end = int(total_files * train_ratio)
        val_end = train_end + int(total_files * val_ratio)

        splits = {
            'train': image_files[:train_end],
            'val': image_files[train_end:val_end],
            'test': image_files[val_end:]
        }

        # íŒŒì¼ ë³µì‚¬
        for split, files in splits.items():
            print(f"{split}: {len(files)}ê°œ íŒŒì¼")

            for img_file in files:
                # ì´ë¯¸ì§€ ë³µì‚¬
                dst_img = os.path.join(self.dataset_paths[split], os.path.basename(img_file))
                shutil.copy2(img_file, dst_img)

                # ëŒ€ì‘í•˜ëŠ” ë¼ë²¨ íŒŒì¼ ë³µì‚¬
                base_name = os.path.splitext(os.path.basename(img_file))[0]
                src_label = os.path.join(source_dir, 'labels', f"{base_name}.txt")

                if os.path.exists(src_label):
                    dst_label = os.path.join(self.label_paths[split], f"{base_name}.txt")
                    shutil.copy2(src_label, dst_label)

        print("ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ!")


def main():
    """ë°ì´í„°ì…‹ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸"""
    manager = DatasetManager()

    # ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
    manager.create_directory_structure()

    # ë°ì´í„°ì…‹ ìƒíƒœ í™•ì¸
    status = manager.check_dataset_status()

    if not status['has_data']:
        print("\nğŸš€ Roboflow ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì˜µì…˜:")
        print("1. ë¹ ë¥¸ ë‹¤ìš´ë¡œë“œ (fire-wrpgm, 979ê°œ ì´ë¯¸ì§€)")
        print("2. ëŒ€ìš©ëŸ‰ ë‹¤ìš´ë¡œë“œ (fire-smoke-detection, 6391ê°œ ì´ë¯¸ì§€)")
        print("3. ëŒ€í™”í˜• ë‹¤ìš´ë¡œë”")

        choice = input("\nì„ íƒí•˜ì„¸ìš” (1-3, Enter=ê±´ë„ˆë›°ê¸°): ").strip()

        if choice == '1':
            api_key = input("Roboflow API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            if api_key:
                manager.quick_download_fire_dataset(api_key)
        elif choice == '2':
            api_key = input("Roboflow API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            if api_key:
                manager.quick_download_large_dataset(api_key)
        elif choice == '3':
            manager.download_roboflow_dataset(interactive=True)

        # ë‹¤ìš´ë¡œë“œ í›„ ë‹¤ì‹œ ìƒíƒœ í™•ì¸
        status = manager.check_dataset_status()

    if status['has_data']:
        # ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€ ë¶„ì„
        print("\nğŸ“Š ë°ì´í„°ì…‹ ë¶„ì„ ì‹œì‘...")
        manager.validate_dataset_format()
        manager.analyze_class_distribution()
        manager.visualize_dataset_samples()
        print("âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ!")
    else:
        print("\nâš ï¸ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ ë‹¤ìš´ë¡œë“œ ì˜µì…˜ì„ ì‚¬ìš©í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()